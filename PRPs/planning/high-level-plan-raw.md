High level plan.

This document captures our intent, and how we plan to execute the project to deliver on the hackathon.

Context files:
- The initial requriements as stated by Nexus MD can be found in PRPs/pmo/context/initial-requirements.md
- Additional Q&A documents were generated by NexusMD can be found in PRPs/pmo/context/nexus_md_qa.md
- Some sample data can be found in PRPs/pmo/context/sample_data.md
- To better understand the MBS data, the following URL can be used. Here is the URL for MBS code 23:
https://www9.health.gov.au/mbs/fullDisplay.cfm?type=item&q=23&qt=item&criteria=23
You can replace the number 23 with any other code number to get the relevant code notes.


The general strategy is to build a minimum viable product that works from end to end, then focus on depth once this initial product is productionised, and iterate.

Phase 1: Building MVP. This is done in parallel to phase 2.

1. Build a pipeline in python that can:
    1.1 take doctors notes as a string
    1.2 Use only the initial descriptions for each code (ignoring the Additional Notes for now) to determine which codes are most relevant. We will likely create some kind of RAG/ Vector DB using the code numbers and the descriptions from the XML file. The structure of the XML file can be found here: https://www.mbsonline.gov.au/internet/mbsonline/publishing.nsf/Content/FAQ-XML_Help
    1.3 It would return the top n (likley 20) most relevant codes
    1.4 There would be some kind of reasoning LLM to justify which codes are most relevant to the doctors notes/ sessios, and why
    1.5 It would then return a structured JSON. Final structure is TBD, but would show at a minimum: Eligible code, clear reasoning for code, and which specific string(s) in the original notes are responsible for this reasoning.
    Note: We understand that to make this more accurate with regards to eligbility criteria, we would need to also somehow pass in the Additonal Notes (AN). We will work on this in phase 2.

2. Once we have the pipeline working, we want to create a REST API endpoint that uses POST. The idea is someone would send the doctors notes as a string, and it would return the json structure. Would probably use FAST API or something simple to serve this.

3. Build a simple front end in react that would allow a doctor to upload notes, and see the result. It would do a POST to the API endpoint we created, and return the results in a pleasing visual manner. The requirements are still TBD.

4. We will also need to create some way of assessing accuracy, and to allow the users to assess the output and give a thumbs up/ thumbs down to give feedback on how well the AI is doing.

5. Once this is all working locally, we want to productionise. Not sure exactly how to do this for the front end and backend. But using GCP Cloud Run probably, maybe vercel for front end?

6. Once this is working properly end to end, we will integrate phase 2.

Phase 2 - Incorporating Addational Notes. This is done in parallel to phase 1.

The goal of this phase is to intelligently preprocess and parse the Additional Notes for each Code through to the LLM so it can make better assessments as to which MBS items are relevent and eligible.
1. Develop a way to intelligently preprocess the additional notes
2. Store these Additional Notes intelligently. Likely through some kind of DataBase.
3. Use RAG/ Vector DB or MCP servers to allow it to intelligently serve relevant AN to the LLM
4. Update the LLM to be able to take in this additional information from the AN to serve a more accurate recommendation with regards to relevant billing items.

Phase 3 - If Phase 1 and Phase 2 work, then we will look to somehow do an offline version that utilises Ollama or some local LLM tool for inferencing. This would allow the whole systemt to be on a laptop and not connected to internet, to alleviate any privacy concerns.